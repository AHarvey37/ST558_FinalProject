---
title: "Modeling"
author: "Andrew Harvey"
format: html
editor: visual
---

# Modeling File

## Introduction Section

|   This project will use the "diabetes_binary_health_indicators_BRFSS2015" data set. According [Kaggle.com](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data) this data set contains 253,680 observation where the response variable is whether the observed individual does or does not not have diabetes (0 or 1 respectively) or has pre-diabetes/diabetes (1). The original data set contains 22 variables most of which are categorical. We have limited the variables to those below:

1.  Diabetes_binary (response variable) - This variable illustrates if the subject has or does not have diabetes. 
2.  HighBP (Categorical) - This is a binary variable describing whether or not the subject has high blood pressure.
3.  HighChol (Categorical) - This is a binary variable describing whether or not the subject has high cholesterol.
4.  Smoker (Categorical) - This is a binary variable describing whether or not the subject has smoked at least 100 cigarettes in their lifetime. 100 cigarettes is equal to 5 packs.
5.  HeartDiseaseorAttack (Categorical) - This is a binary variable describing whether or not the subject has coronary heart disease or myocardial infarction (a heart attack).  
6.  PhysActivity (Categorical) - This is a binary variable describing whether or not the subject has conducted physical activity (outside of their job) in the past 30 days.
7.  HvyAlcoholConsump (Categorical) - This is a binary variable describing whether or not the subject, if male, consumes 14 or more alcoholic drinks per week, or if female, consumes 7 or more alcoholic drinks per week. 
8.  MentHlth - This variable is a scale from 1 to 30 of how many days the subject has had POOR mental health.
9.  Age (Categorical) - This variable breaks age into 13 levels which are 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-80, and 80 or older.


|    Our first steps are to load the applicable libraries. In this file we will be modeling using the caret package and we will also use the tidyverse package, specifically dplyr, to manipulate our data. Our second step will be to load in our raw data and convert the variables we will be using to factors and remove the unused variables. 

```{r Libraries and Raw data, warning=FALSE, message=FALSE,}
library(tidyverse)
library(caret)
library(tree)
```


```{r Read in Data and Set Factors}
rawData <- read.csv("./diabetes_binary_health_indicators_BRFSS2015.csv")

#create a new data frame for cleaning and converts all binary variables into factors
cleaned<- rawData|>
  select(Diabetes_binary,HighBP,HighChol,HvyAlcoholConsump,Smoker,PhysActivity,Age,HeartDiseaseorAttack,MentHlth,BMI)|>
  mutate(Diabetes_binary = factor(Diabetes_binary,labels = c("No","Yes")),
         Age = as.factor(Age),
         HighBP = as.factor(HighBP),
         HighChol = as.factor(HighChol),
         HvyAlcoholConsump = as.factor(HvyAlcoholConsump),
         Smoker = as.factor(Smoker),
         PhysActivity = as.factor(PhysActivity),
         HeartDiseaseorAttack=as.factor(HeartDiseaseorAttack),
         MentHlth=as.factor(MentHlth))
```


### Splitting Data

|   Our next step will be to split the data into a training set and a test set. We will set the seed to 8 to allow for reproduction by others. We then split the data using the \createdatapartition function from the caret package. The split will take 70% of the data and place it into the training set and then the other 30% into the test set. We will use the training set to train our competing models and then use the test set to predict the response variable of the model, diabetes_binary. 


```{r Split Data}
# set seed for predictability
set.seed(8)

# Create a Vector to use to split data. Used createdatapartition to help maintain the ratio of diabates positive to diabetes negative
trainingVec <- createDataPartition(cleaned$Diabetes_binary,
                                   p = .7,
                                   list = FALSE)

# Split data into training and test sets
## Training set
diabetesTrain <- cleaned[trainingVec,]
## Test set
diabetesTest <- cleaned[-trainingVec,]

```


### LogLoss

| For this project we will analyze the logloss of our models rather than looking at the prediction outcome of the model. Logloss is a measurement of prediction used in machine learning. In essence logloss measures how accurate a prediction is to the actual resulting value. The closer the prediction is to the actual value the lower the logloss, lower logloss is preferred. Conversely, the further the prediction is from the actual value the higher the logloss. For example, if a prediction value was 0.95 and the actual was 1 the logloss would be very low, around 0.05, and thus very good. Logloss is computed as such: $$-logLoss = -\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{C}y_{ij}log(p_{ij})$$
This may be a better metric to use in certain cases due to the final logloss. The final logloss is the averaged logloss across the model. This will tell the user how well the model performed overall, with the lower the number the better the model. 
```{r set train control and 5 fold cross-validation using mnLogLoss}
# make Train Control Variable with 5 fold cross-validation
trctrl<- trainControl(method = "cv",
                      number = 5,
                      classProbs = TRUE,
                      summaryFunction = mnLogLoss)
```

## Logistic Regression Models

|    For our first model type we will use a Bayes Logistic regression model. Logistic regression models explores the relationship between the independent variables and the response variable. In this case we are looking at a binary classification, whether the response variable will be 0 or 1 (has diabetes or does not), so the model will use the logit function to predict this relationship.

```{r train and fit glm}
# Generalized Linear Model
Diabetes_logFit1<-train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker,
                       data = diabetesTrain,
                       method = "bayesglm",
                       trControl = trctrl,
                       metric = "logLoss",
                       family = "binomial")

# Generalized Linear Model
Diabetes_logFit2<-train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker+PhysActivity+Age,
                       data = diabetesTrain,
                       method = "bayesglm",
                       trControl = trctrl,
                       metric = "logLoss",
                       family = "binomial")

# Generalized Linear Model
Diabetes_logFit3<-train(Diabetes_binary ~ .,
                       data = diabetesTrain,
                       method = "bayesglm",
                       trControl = trctrl,
                       metric = "logLoss",
                       family = "binomial",
                       #tuneGrid = expand.grid(nIter = 3)
                       )

# Create a Comparison Table
#Diabetes_logFit3$results<-rename(Diabetes_logFit3$results, parameter = nIter)

Comparison <- data.frame(rbind(Diabetes_logFit1$results,Diabetes_logFit2$results,Diabetes_logFit3$results))|>
  mutate(Model_type = c("1","2","3"))|>
  select(Model_type,logLoss,logLossSD)

Comparison

# Best model = BayesGLM
```

## Classification trees

|   The second model type that will be used is the classification tree method. This model takes is a decision tree and we will use a 'CART' method. The classification and regression tree (CART) looks at how the response variable interacts with all other variables by growing a tree. A tree is grown by splitting each prediction into its own path based on a specific prediction value, i.e. if a prediction value is above a certain value then it will fork to one direction and if it is under the specified value then it will fork to the other direction. This will continue until each node reaches a terminal level. This model type is prone to over-fitting and thus we must implement pruning methods to ensure that the model is not over fitted.  

```{r Classification trees}

cart_TreeFit<- train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker,
                       data = diabetesTrain,
                       method = "rpart",
                       trControl = trctrl,
                       metric = "logLoss",
                       #family = "binomial",
                       tuneGrid = expand.grid(cp = seq(0,1,by=.1))
                       )
cart_TreePredict <- predict(cart_TreeFit,
                            newdata = diabetesTest,
                            type = "prob")
cart_TreePredict

cart_TreeFit2<- train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker+PhysActivity+Age,
                       data = diabetesTrain,
                       method = "rpart",
                       trControl = trctrl,
                       metric = "logLoss",
                       #family = "binomial",
                       tuneGrid = expand.grid(cp = seq(0,1,by=.1))
                       )
cart_TreePredict2 <- predict(cart_TreeFit2,
                            newdata = diabetesTest,
                            type = "prob")

cart_TreeFit3<- train(Diabetes_binary ~ .,
                       data = diabetesTrain,
                       method = "rpart",
                       trControl = trctrl,
                       metric = "logLoss",
                       #family = "binomial",
                       tuneGrid = expand.grid(cp = seq(0,1,by=.1))
                       )
cart_TreePredict3 <- predict(cart_TreeFit3,
                            newdata = diabetesTest,
                            type = "prob")


cart_TreeFit$results
cart_TreeFit2$results
cart_TreeFit3$results

Comparison_tree<- data.frame(rbind(cart_TreeFit$results[1:3,],
                                   cart_TreeFit2$results[1:3,],
                                   cart_TreeFit3$results[1:3,]))|>
   mutate(Model_type = c("1","1","1","2","2","2","3","3","3"))|>
  select(Model_type,cp,logLoss,logLossSD)

Comparison_tree

# Best Tree = rpart w/ cp =0.0

```



## Random Forests

|   The final model type that we will examine is the Random Forest. The Random Forest method is very similar to the classification tree model type but instead of growing one tree model type grows many tree. While this may seem like it would be easily more beneficial to the classification tree method the random forest loses some of the specificity that the classification tree has since it averages many trees together. This average is an attempt to increase accuracy but it does not always improve.


```{r random forests}
rf_Fit<- train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker,
               data = diabetesTrain,
               method = "ranger",
               trControl = trctrl,
               metric = "logLoss",
               tuneGrid = expand.grid(mtry = 3,
                                      splitrule = "extratrees",
                                      min.node.size = 100)
                       )

rf_Pred<- predict(rf_Fit,
                  newdata = diabetesTest,
                  type = "prob")

rf_Fit2<- train(Diabetes_binary ~ HighBP+HighChol+BMI+HvyAlcoholConsump+Smoker+PhysActivity+Age,
                data = diabetesTrain,
                method = "ranger",
                trControl = trctrl,
                metric = "logLoss",
                tuneGrid = expand.grid(mtry = 3,
                                       splitrule = "extratrees",
                                       min.node.size = 100)
                       )

rf_Pred2<- predict(rf_Fit2,
                  newdata = diabetesTest,
                  type = "prob")

rf_Fit3<- train(Diabetes_binary ~ .,
                data = diabetesTrain,
                method = "ranger",
                trControl = trctrl,
                metric = "logLoss",
                tuneGrid = expand.grid(mtry = 3,
                                       splitrule = "extratrees",
                                       min.node.size = 100)
                       )

rf_Pred3<- predict(rf_Fit3,
                  newdata = diabetesTest,
                  type = "prob")


rf_Fit$results
rf_Fit2$results
rf_Fit3$results

Comparison_forest<- data.frame(
  rbind(
    rf_Fit$results[,c("logLoss","logLossSD")],
    rf_Fit2$results[,c("logLoss","logLossSD")],
    rf_Fit3$results[,c("logLoss","logLossSD")])|>
  mutate(Model_type = c("1","2","3"))|>
  select(Model_type,logLoss,logLossSD))

Comparison_forest

# Best Forest = range
```

## Final Model selection 

|   In this final section we take the best models from above and compare them to see which is the overall best model. We do this be comparing the lowest logloss from the three models when they are predicting on the test data set. Since we have already trained all three models we will use the predict function to predict the results of the test set. We will then look at the logloss of each model and select the lowest logloss as our best model.

```{r compare best models}

bayesGLMPredict<- predict(Diabetes_logFit2,
                          newdata = diabetesTest,
                          type = "prob")|>
  as_tibble()
bayesGLMPredict

cart_TreePredict<-predict(cart_TreeFit,
                          newdata = diabetesTest,
                          type = "prob")|>
  as_tibble()

cart_TreePredict

rf_Pred<-predict(rf_Fit,
                 newdata = diabetesTest,
                 type = "prob")|>
  as_tibble()

rf_Pred

Logloss<- function(real,prediction){
  results<- -1/length(real)*(sum(real*log(prediction)+(1-real)*log(1-prediction)))
  return(results)
}

final_compar<-data.frame(rbind(Logloss(rawData$Diabetes_binary,bayesGLMPredict),
                               Logloss(rawData$Diabetes_binary,cart_TreePredict),
                               Logloss(rawData$Diabetes_binary,rf_Pred)))|>
  mutate(BestModel = c("Bayes GLM", "Classification Tree", "Random Forest"))

names(final_compar)<- c("LogLoss","Mehod")
final_compar

# best model = Classification tree with all variables
```

